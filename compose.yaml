services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: llm-debate-backend
    ports:
      - "8080:8080"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
    volumes:
      - ./backend/debate.db:/app/debate.db
    networks:
      - llm-debate-network
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: llm-debate-frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    networks:
      - llm-debate-network
    restart: unless-stopped

networks:
  llm-debate-network:
    driver: bridge

volumes:
  db-data:
